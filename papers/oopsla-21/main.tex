%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[acmsmall, anonymous]{acmart}

% ----------------------------------------

%% Packages

\usepackage{wrapfig}
\usepackage{xcolor}
\usepackage{color}
\usepackage{multicol}
\usepackage[ruled,vlined,noend]{algorithm2e}
\usepackage{xspace}
\usepackage{tikz}
\usepackage{tikzscale}
\usepackage{pgfplots}
\usepackage{paralist}
\pgfplotsset{compat=1.3}

\usetikzlibrary{trees}

\makeatletter
\patchcmd{\@verbatim}
  {\verbatim@font}
  {\verbatim@font\footnotesize}
  {}{}
\makeatother

\let\oldv\verbatim
\let\oldendv\endverbatim

\def\verbatim{\par\setbox0\vbox\bgroup\oldv}
\def\endverbatim{\oldendv\egroup\fboxsep0pt \noindent\colorbox[gray]{0.95}{\usebox0}\par}

% ----------------------------------------

%% Rights management information. This information is sent to you when you
%% complete the rights form. These commands have SAMPLE values in them; it is
%% your responsibility as an author to replace the commands and values with
%% those provided to you when you complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021}
%% \acmDOI{10.1145/1122445.1122456}

%% These commands are for a JOURNAL article.
\acmConference[OOPSLA '21]{OOPSLA '21: ACM SIGPLAN conference on Systems,
  Programming, Languages, and Applications}{October 17--22 2021}{Chicago, IL}

%% \acmJournal{JACM}
%% \acmVolume{37}
%% \acmNumber{4}
%% \acmArticle{111}
%% \acmMonth{8}

%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}

% ----------------------------------------
%% Macros

\newcommand{\quickcheck}{\textit{QuickCheck}\xspace}
\newcommand{\quickchick}{\textit{QuickChick}\xspace}
\newcommand{\fuzzchick}{\textit{FuzzChick}\xspace}
\newcommand{\mutagen}{\textsc{Mutagen}\xspace}

% ----------------------------------------

%% end of the preamble, start of the body of the document source.

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{\mutagen: Working title}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Agust\'in Mista}
\email{mista@chalmers.se}
\affiliation{%
  \institution{Chalmers University of Technology}
  \city{Gothenburg}
  \country{Sweden}
}

\author{Alejandro Russo}
\email{russo@chalmers.se}
\affiliation{%
  \institution{Chalmers University of Technology}
  \city{Gothenburg}
  \country{Sweden}
}

%% By default, the full list of authors will be used in the page headers. Often,
%% this list is too long, and will overlap other information printed in the page
%% headers. This command allows the author to define a more concise list of
%% authors' names for this purpose.

%% \renewcommand{\shortauthors}{Mista and Russo}


% ----------------------------------------
%% The abstract is a short summary of the work to be presented in the article.

\begin{abstract}
  Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec facilisis
  facilisis, est dui fermentum leo, quis tempor ligula erat quis odio. Nunc
  porta vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum. Aliquam
  posuere. Nunc aliquet, augue nec adipiscing interdum, lacus tellus malesuada
  massa, quis varius mi purus non odio. Pellentesque condimentum, magna ut
  suscipit hendrerit, ipsum augue ornare nulla, non luctus diam neque sit amet
  urna. Curabitur vulputate vestibulum lorem. Fusce sagittis, libero non
  molestie mollis, magna orci ultrices dolor, at vulputate neque nulla lacinia
  eros. Sed id ligula quis est convallis tempor. Curabitur lacinia pulvinar
  nibh. Nam a sapien.
\end{abstract}

% ----------------------------------------

%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm. Please
%% copy and paste the code instead of the example below.
\begin{CCSXML}
% CCS XML here
\end{CCSXML}

%% \ccsdesc[500]{Computer systems organization~Embedded systems}
%% \ccsdesc[300]{Computer systems organization~Redundancy}
%% \ccsdesc{Computer systems organization~Robotics}
%% \ccsdesc[100]{Networks~Network reliability}

% ----------------------------------------

%% Keywords. The author(s) should pick words that accurately describe the work
%% being presented. Separate the keywords with commas.
\keywords{random testing, mutations, heuristics}

% ----------------------------------------

%% This command processes the author and affiliation and title information and
%% builds the first part of the formatted document.
\maketitle

% ----------------------------------------

\section{Introduction}
\label{sec:intro}

Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec facilisis
facilisis, est dui fermentum leo, quis tempor ligula erat quis odio. Nunc porta
vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum. Aliquam posuere.
Nunc aliquet, augue nec adipiscing interdum, lacus tellus malesuada massa, quis
varius mi purus non odio. Pellentesque condimentum, magna ut suscipit hendrerit,
ipsum augue ornare nulla, non luctus diam neque sit amet urna. Curabitur
vulputate vestibulum lorem. Fusce sagittis, libero non molestie mollis, magna
orci ultrices dolor, at vulputate neque nulla lacinia eros. Sed id ligula quis
est convallis tempor. Curabitur lacinia pulvinar nibh. Nam a sapien.

The contributions of this work are:

\begin{itemize}
\item Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec
  facilisis facilisis, est dui fermentum leo, quis tempor ligula erat quis odio.
  Nunc porta vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum.
  Aliquam posuere. Nunc aliquet, augue nec adipiscing interdum, lacus tellus
  malesuada massa, quis varius mi purus non odio.
\item Pellentesque condimentum,
  magna ut suscipit hendrerit, ipsum augue ornare nulla, non luctus diam neque
  sit amet urna. Curabitur vulputate vestibulum lorem. Fusce sagittis, libero
  non molestie mollis, magna orci ultrices dolor, at vulputate neque nulla
  lacinia eros. Sed id ligula quis est convallis tempor. Curabitur lacinia
  pulvinar nibh. Nam a sapien.
\item Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec
  facilisis facilisis, est dui fermentum leo, quis tempor ligula erat quis odio.
  Nunc porta vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum.
  Aliquam posuere. Nunc aliquet, augue nec adipiscing interdum, lacus tellus
  malesuada massa, quis varius mi purus non odio.
\item Pellentesque condimentum, magna ut suscipit hendrerit, ipsum augue ornare
  nulla, non luctus diam neque sit amet urna. Curabitur vulputate vestibulum
  lorem. Fusce sagittis, libero non molestie mollis, magna orci ultrices dolor,
  at vulputate neque nulla lacinia eros. Sed id ligula quis est convallis
  tempor. Curabitur lacinia pulvinar nibh. Nam a sapien.
\end{itemize}

% ----------------------------------------

\section{Background}
\label{sec:background}

In this section we briefly introduce the concept of Property-based Testing along
with \quickcheck, the most popular tool of this sort and often considered as the
baseline when comparing PBT algoritms.
%
Moreover, we describe the ideas and limitations behind \fuzzchick, which
enhances the PBT approach with execution information and serves as the
foundation for \mutagen.
%
\fuzzchick is implemented as an extension of \quickchick, Coq's own
reimplementation of \quickcheck.

\subsection{Property-Based Testing and \quickcheck}

Property-based testing is a powerful technique for finding bugs without having
to write test cases by hand.
%
Originally introduced by \citet{quickcheck} in tandem with the first version of
\quickcheck, this technique focuses on aiming the developer's efforts into
testing systems via executable specifications using randomly generated inputs.
%
Moreover, tools like \quickchick and Isabelle's \quickcheck demonstrate
that PBT can also be used in the formal verification realm.
%
There, one can quickly spot bugs in system specifications before directing the
efforts into pointlessly trying to prove bogus propositions.


In the simplest form, there are four main elements the user needs to provide in
order to perform property-based testing on their systems:
%
\begin{itemize}
\item one or more \emph{executable properties}, often implemented simply as a
  boolean predicates,
\item \emph{random data generators}, used to repeatedly instantiate the testing
  properties,
\item \emph{printers}, used to show the user the random inputs that falsify some
  testing property (the counterexample) whenever a bug is found, and
\item \emph{shrinkers}, to minimize counterexamples making them easier to
  understand by humans.
\end{itemize}

\noindent In this work we focus solely on the first two elements introduced
above, namely the testing properties and the random data generators used to feed
them.
%
Printers and shrinkers, for the most part, can be obtained automatically using
generic programming capabilities present in the compiler, and although being
crucial for the testing process as a whole, their role becomes irrelevant when
it comes to \emph{finding} bugs.

\begin{algorithm}[ b]
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{QC}{Loop}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\QC{P, N, gen}}{
    i $\gets$ 0\;
    \While{i $<$ N}{
      x $\gets$ Sample(gen)\;
      \lIf{\KwNot P(x)}{\KwRet Bug(x)}
      i $\gets$ i+1 \;
    }
    \KwRet Ok\;
  }
\caption{\label{algo:quickcheck}\quickcheck Testing Loop}
\end{algorithm}

Perhaps the simplest PBT technique is to repeatedly generate random inputs and
instantiate the testing properties until they either get falsified by a
counterexample, or we ran a sufficiently large amount of tests --- suggesting
that the properties holds.
%
\quickcheck implements a testing loop that closely follows this simple idea,
which is outlined in Algorithm \ref{algo:quickcheck}, where $P$ is the testing
property, $N$ is the maximum number of tests to perform, and $gen$ is the random
generator to be used to instantiate $P$.


To illustrate this technique, let us focus on the same motivating example used
by \citeauthor{lampropoulos2019coverage}, who propose a simple property defined over
binary trees.
%
Such data structure can be easily defined in Haskell using a custom data type
with two data constructors for leaves and branches respectively:

\begin{verbatim}
data Tree a = Leaf a | Branch (Tree a) a (Tree a)
\end{verbatim}

\noindent The type parameter \texttt{a} indicates that trees can be instantiated
using any other type as payload, so the value \texttt{Leaf Bool} has type
\texttt{Tree Bool}, whereas the value \texttt{Branch (Leaf 1) 2 (Leaf 3)} has
type \texttt{Tree Int}.
%
Then, we can define tree reflections using a simple recursive function that
pattern matches against the two possible constructors, inverting the order of
the subtrees whenever it encounters a branch:

\begin{verbatim}
mirror :: Tree a -> Tree a
mirror (Leaf x)       = Leaf x
mirror (Branch l x r) = Branch (mirror r) x (mirror l)
\end{verbatim}

Later, a reasonable requirement to assert for is that \texttt{mirror} must be
\emph{involutive}, i.e., reflecting a tree twice always yields the original
tree.
%
We can simply capture this property using a boolean predicate written as a
normal function:

\begin{verbatim}
prop_mirror :: Tree Int -> Bool
prop_mirror t = mirror (mirror t) == t
\end{verbatim}

\noindent For simplicity, here we instantiate the tree payload with integers,
altough this predicate should clearly hold for any other type with a properly
defined notion of equality as well.


With our simple specification in place, the last missing piece is a random
generator of trees.
%
In \quickcheck, this is usually done via the type class mechanism, instantiating
the \texttt{Arbitrary} type class, providing a random generator as the
implementation of the overloaded \texttt{arbitrary} operation:

\begin{verbatim}
instance Arbitrary a => Arbitrary (Tree a) where
  arbitrary = sized gen
    where
      gen 0 = do { x <- arbitrary; return (Leaf x) }
      gen n = oneof [ do {x <- arbitrary; return (Leaf x) }
                    , do {l <- gen (n-1); x <- arbitrary; r <- gen (n-1); return (Branch l x r)} ]
\end{verbatim}

\noindent Let us break this definition into parts.
%
The first line states that we will provide an \texttt{Arbitrary} instance for
trees with payload of type \texttt{a}, provided that values of type \texttt{a}
can also be randomly generated.
%
This allows us to use \texttt{arbitrary} to generate \texttt{a}'s inside the
definition of our tree generator.


Moreover, \quickcheck internally keeps track of the \emph{maximum generation
  size}, a parameter that can be tuned by the user in order to limit the size of
the randomly generated values.
%
Our definition exposes this internal parameter via \quickcheck's \texttt{sized}
combinator, allowing us to parameterize the maximum size of the randomly
generated trees.
%
If the generation size is zero (\texttt{gen 0}), our generator is limited to
produce just leaves with randomly generated payloads.
%
In turn, when the generation size is strictly positive (\texttt{gen n}), the
generator is able to perform a random uniform choice between generating either a
single leaf or a branch.
%
When generating branches, the generator calls itself recursively in order to
produce random subtrees (\texttt{gen (n-1)}).
%
Notice the importance of reducing the generation size on each recursive call.
%
This way we ensure that randomly generated trees using a generation size
\texttt{n} are always finite and have at most \texttt{n} levels.

Finally, we are ready to let \quickcheck test \texttt{prop\_mirror} against a
large number of inputs (100 by default) produced by our brand new random tree
generator:

\begin{verbatim}
quickCheck prop_mirror
+++ Ok ####
\end{verbatim}

\noindent Should we mistakenly implement \texttt{mirror}, e.g., by dropping the
right subtree altogether:

\begin{verbatim}
mirror (Branch l x r) = Branch (mirror l) x (mirror l)
\end{verbatim}

\noindent then \quickcheck will quickly falsify \texttt{prop\_mirror}, reporting
a minimized counterexample that we can use to find the root of the issue:

\begin{verbatim}
quickCheck prop_mirror
*** Failed ####
\end{verbatim}

At this point, it is clear that the \emph{quality} of our random generators is
paramount to the performance of the overall PBT process.
%
Random generators that rarely produce interesting values will fail to trigger
bugs in our code, potentially leaving entire parts of the codebase virtually
untested.


Recalling our tree generator, the reader (far from mistaken) might already have
imagined better ways for implementing it.
%
For most practical purposes, this generator is in fact quite bad.
%
However, it follows a simple type-directed fashion, and it is a good example of
what to expect from a random generator synthesized automatically using a process
that knows very little about the values to be generated apart from their
(syntactic) data type structure.

As introduced earlier, there exist multiple tools that can automatically derive
better random generators solely from the static information present in the
codebase.
%
%% Such tools vary on the degree of invariants and requirements
%% %
%% However, such approaches are unable to derive useful generators whenever the
%% target data involves complex invariants that cannot be easily extracted from the
%% codebase or that cannot be easily expressed in terms of inductive relations.
%
Sadly, these tools lack the domain knowledge required to generate random data
with complex invariants --- especially those present in programming languages
like well-scopedness and well-typedeness.


In particular, automatically derived generators are remarkably uneffective when
used to test properties with sparse preconditions.
%
Let us continue with the example by \citeauthor{lampropoulos2019coverage} to
illustrate this problem in more detail.
%
For this, consider that we want to use our \texttt{Tree} data type to encode
binary-search trees (BST).
%
Then, given a predicate \texttt{isBST} that asserts if a tree satisfies the BST
invariants, we might want to use it as pre- and post-condition to assert that
BST operations like \texttt{insert} preserve them:

\begin{verbatim}
prop_bst_insert :: Tree a -> a -> Bool
prop_bst_insert t a =
  isBST t ==> isBST (insert a t)
\end{verbatim}

\noindent Attempting to test this property using \quickcheck does not work well:

\begin{verbatim}
quickCheck prop_bst_insert
*** Gave up! ####
\end{verbatim}

\noindent Here, \quickcheck discards random inputs as soon as it finds they do
not pass the precondition (\texttt{isBST t}).
%
Sadly, most of the inputs generated by our na\"ive generator suffer from this
problem, and the interesting part of the property (\texttt{isBST (insert a t)})
is tested very sporadically as a result.


At this point it is reasonable to think that, to obtain the best results when
using PBT over complex systems, one is forced to put a large amount of time on
developing manually-written generators.
%
In practice, that is most often the case, no automatic effort can beat a
well-thought manually-written generator that produces interesting complex values
and finds bugs in very few tests.
%
Not all is lost, however.
%
It is still possible to obtain acceptable results automatically by incorporating
dynamic information from the system under test into the testing loop.
%
The next subsection introduces the clever technique used by \fuzzchick to find
bugs in complex systems while using simple automatically derived random
generators.

%% Far from trying to compete against manual-efforts, our work focuses on improving
%% automatic approaches so they can be used paliatively in earlier development
%% stages.

\subsection{Coverage-Guided Property-Based Testing with \fuzzchick}

To alleviate the problem of testing properties with sparse preconditions while
using simple automatically derived random generators, \fuzzchick introduces
\emph{coverage-guided property-based testing} (CGPT) by enhancing the testing
process with two key characteristics:
%
\begin{inparaenum}
\item \emph{target code instrumentation}, to capture execution information from
  each test case; and
\item \emph{high-level, well-typed mutations}, to produce syntactically valid
  test cases by altering existing ones at the datatype level.
\end{inparaenum}

Using code instrumentation in tandem with mutations is a well-known technique in
the fuzzing community.
%
Generic fuzzing tools like AFL, libFuzzer or HonggFuzz, as well as
language-specific ones like Crowbar use execution traces to recognize
interesting test cases, e.g, those that exercise previously undiscovered parts
of the target code.
%
Later, such tools use generic mutators to combine and produce new test cases
from previously executed interesting ones.
%
\fuzzchick, however, does this in a clever way.
%
Instead of mutating any previously executed test case that discovers a new part
of the code, \fuzzchick integrates these fuzzing techniques into the PBT testing
loop itself.


Since it is possible to distinguish semantically valid test cases from invalid
ones, i.e., those passing the sparse preconditions of our testing properties as
opossed to those that are discarded early, \fuzzchick exploits this information
in order to focus the testing efforts into mutating valid test cases with a
higher priority than those that were discarded.


In addition, high-level mutators are better suited for producing syntactically
valid mutants, avoiding the time wasted by using generic low-level mutators that
act at the ``serialized'' level and know very little about the structure of the
generated data, thus producing syntactically broken mutants most of the time.
%
This grammar-aware mutation technique has shown to be quite useful when fuzzing
systems accepting structurally complex inputs.
%
Tools like Criterion, XSmith and LangFuzz use existing grammars to tailor the
generic mutators to the specific input structure used by the system under test.
%
In \fuzzchick, external grammars are not required.
%
The datatypes used by the inputs of the testing properties already describe the
structure of the random data we want to mutate in a concrete manner, and
specialized mutators acting at the data constructor level can be automatically
derived directly from their definition.

The next subsections describe \fuzzchick's testing loop and well-typed mutations
in detail.

\subsubsection{Testing loop}

Outlined in Algorithm \ref{algo:fuzzchick:loop}, the process starts by creating
two queues, \textit{QSucc} and \textit{QDisc} for valid and discarded previously
executed test cases, respectively.
%
Enqueued values are stored along with a given mutation energy, that controls how
many times a given test case can be mutated before being finally discared.


Once inside of the main loop, \fuzzchick picks the next test case using a simple
criterion: if there are valid values enqueued for mutation, it picks the first
one, mutates it and returns it, decreasing its energy by one.
%
If \textit{QSucc} is empty, then the same is attempted using \textit{QDisc}.
%
If none of the mutation queues contain any candidates, \fuzzchick generates a
new value from scratch.
%
This selection process is illustrated in detail in Algorithm
\ref{algo:fuzzchick:pick}.


Having selected the next test case, the main loop proceeds to execute it,
capturing both the result (passed, discarded, or failed) and its execution trace
over the system under test.
%
If the test case fails, it is immediately reported as a bug.
%
If not, \fuzzchick evaluates whether it was interesting (i.e., it exercises a
new path) based on its trace information and the one from previously executed
test cases (represented by \textit{TLog}).
%
If the test case does in fact discover a new path, it is enqueued at the end of
its corresponding queue, depending on whether it passed or was discarded.
%
This process alternates between generation and mutation until a bug is found or
we reach the test limit.


The energy assigned to each test case follows that of AFL's power schedule: more
energy to test cases that lead to shorter executions, or that discover more
parts of the code.
%
Moreover, to favour mutating interesting valid test cases, they get more energy
than those that were discarded.



\begin{figure}[t]
\begin{multicols}{2}

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{FC}{Loop}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\FC{P, N, gen, mut}}{
    i $\gets$ 0\;
    TLog, QSucc, QDisc $\gets$ $\varnothing$;\;
    \While{i $<$ N}{
      x $\gets$ Pick(QSucc, QDisc, gen, mut)\;
      (result, trace) $\gets$ WithTrace(P(x))\;
      \lIf{\KwNot result}{\KwRet Bug(x)}
      \If{Interesting(TLog, trace)}{
        e $\gets$ Energy(TLog, x, trace)\;
        \eIf{\KwNot Discarded(result)}{
          Enqueue(QSucc, (x, e))\;
        }{
          Enqueue(QDisc, (x, e))\;
        }
      }
      i $\gets$ i+1\;
    }
    \KwRet Ok\;
  }
\caption{\label{algo:fuzzchick:loop}\fuzzchick Testing Loop}
\end{algorithm}

\columnbreak

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{Pick}{Pick}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\Pick{QSucc, QDisc, gen, mut}}{
    \If{\KwNot Empty(QSucc)}{
      (x,e) $\gets$ Deque(QSucc)\;
      \If{e $>$ 0}{
        PushFront(QSucc, (x, e-1))
      }
      \KwRet Sample(mut(x))\;
    }
    \uElseIf{\KwNot Empty(QDisc)}{
      (x,e) $\gets$ Deque(QDisc)\;
      \If{e $>$ 0}{
        PushFront(QDisc, (x, e-1))
      }
      \KwRet Sample(mut(x))\;
    }
    \lElse{\KwRet Sample(gen)}
  }
\caption{\label{algo:fuzzchick:pick}\fuzzchick Seed Selection}
\end{algorithm}

\end{multicols}
\end{figure}

\subsubsection{Well-typed mutations}

Mutators in \fuzzchick are no more than specialized random generators,
parameterized by the original input to be mutated.
%
They use a simple set of mutation operations that are randomly applied at the
datatype level.
%
In simple terms, these operations encompass
%
\begin{inparaenum}
\item \emph{shrinking the value}, replacing its top-level data constructor with
  one that contains a subset of its fields, reusing existing subexpressions;
\item \emph{growing the value}, replacing its top-level data constructor with
  one that contains a superset of its fields, reusing existing subexpressions
  and generating random ones when needed;
\item \emph{returning a subexpression of the same type}; and
\item \emph{mutating recursively}, applying a mutation operation over an
  immediate subexpression.
\end{inparaenum}


\begin{figure}
\begin{verbatim}
mutate_tree :: (a -> Gen a) -> Tree a -> Gen (Tree a)
mutate_tree mutate_a (Leaf x) =
  oneof [ do { x' <- mutate_a x; return (Leaf x')}                     -- Mutate recursively
        , do { l <- arbitrary; r <- arbitrary; return (Node l x r) } ] -- Grow constructor
mutate_tree (Node l x r) =
  oneof [ return l                                                     -- Return subexpression
        , return r                                                     -- Return subexpression
        , return (Leaf x)                                              -- Shrink constructor
        , do { l' <- mutate_tree l; return (Node l' x r) }             -- Mutate recursively
        , do { x' <- mutate_a    x; return (Node l x' r) }             -- Mutate recursively
        , do { r' <- mutate_tree r; return (Node l x r') } ]           -- Mutate recursively
\end{verbatim}
\caption{\label{fig:fuzzchick:mutator}\fuzzchick mutator for the \texttt{Tree} data type. }
\end{figure}

Fig. \ref{fig:fuzzchick:mutator} illustrates a \fuzzchick mutator for our
previously used \texttt{Tree} data type example.
%
Since trees are parametric, for clarity this definition is also parameterized by
a mutator for the payload (\texttt{mutate\_a}), although this can be abstracted
away using the type class system.

%% (where \texttt{mutate\_tree} and
%% \texttt{mutate\_a} can be transparently coerced into an overloaded
%% \texttt{mutate} function.)


In this mutator, branches can be shrinked into leaves by dropping the subtrees,
whereas leaves can grow into branches, by reusing the payload and generating two
random subtrees.
%
Moreover, branches can be replaced with one of their subtrees.
%
Finally, mutations can be recursively applied over both the payload and the
subtrees.
%
At the top level, all these operations are put together using the \texttt{oneof}
combinator that randomly picks one of them with uniform probability.

%
% FuzzChick Limitations
%
\subsubsection{Limitations of \fuzzchick}

\citeauthor{lampropoulos2019coverage} demonstrated empirically that \fuzzchick
lies comfortably in the middle ground between using pure random testing with
na\"ive automatically derived random generators and complex manually-written
ones.
%
Their results suggest that CGPT is an appealing technique for finding bugs while
still using a mostly automated workflow.

However, the authors acknowledge that certain parts of their implementation have
room for improvement, especially when it comes to the mutators design.
%
Moreover, when we recreated the evaluation of the IFC stack machine case study
(described in detail in Section \ref{sec:casestudies}), we found that after 30
runs (as opposed to the 5 runs used original by
\citeauthor{lampropoulos2019coverage}), \emph{\fuzzchick was only able to find 5
  out of the 20 injected bugs with a failure rate of 1}, the hardest one being
found only around 13\% of the time after an hour of testing.
%
These results are presented in detail in Section \ref{sec:evaluation}.


At the light of these observations, we identified several aspects of \fuzzchick
that can be improved upon --- and that constitute the main goal of this work.
%
In no particular order:
%
\begin{itemize}
\item \emph{Mutators distribution:} if we inspect the mutator defined in Fig.
  \ref{fig:fuzzchick:mutator}, there are two compromises that the authors of
  \fuzzchick adopted for the sake of simplicity.
  %
  On one hand, deep recursive mutations are very unlikely, since their
  probability decreases multiplicatively with each recursive call.
  %
  For instance, mutating a subexpression that lies on the third level of a
  \texttt{Tree} happens with a probability smaller than $(1/6)^3 = \sim 0.0046$,
  and this only worsens as the type of the mutated value becomes more complex.
  %
  Hence, \fuzzchick mutators can only be effectively used to transform to
  shallow data structures, potentially excluding interesting applications that
  might require producing deeper valid values, e.g., programming languages,
  network protocols interactions, etc.
  %
  Ideally, mutations should be able to happen on every subexpression of the
  input seed in a reasonable basis.

  On the other hand, using random generators to produce neeeded subexpressions
  when growing data constructors can be dangerous, as we are introducing the
  very same ``uncontrolled'' randomness that we wanted to mitigate in the first
  place!
  %
  If the random generator produces an invalid subexpression (something quite
  likely), this might just invalidate the whole mutated test case.
  %
  We believe that growing data constructors needs to be done carefully.
  %
  For instance, by using just a minimal piece of data to make the overall
  mutated test case type correct.
  %
  If that mutated test case to be interesting, that subexpression can always be
  mutated later.

\item \emph{Enqueuing mutation candidates:} \fuzzchick uses two single queues for
  keeping valid and discarded mutation candidates.
  %
  Whenever a new test case is found interesting, it is placed \emph{at the end
    of its corresponding queue}.
  %
  If this test case happens to have discovered a whole new portion of the target
  code, it will not be further mutated until the rest of the queue ahead of it
  gets processed.
  %
  This can limit the effectiveness of the testing loop if the queues tend to
  grow more often than they tend to shrink, as interesting mutation candidates
  can get buried at the end of a long queue that only exercises the same portion
  of the target code.
  %
  In the extreme case, they might not processed at all within the testing budget.
  %
  Ideally, one would like a mechanism that prioritizes mutating test cases
  that discovers new portions of the code right away, and that is capable of
  jumping back and forth from mutation candidates whenever this happens.
  %
  We show in Section \ref{sec:heuristics} how this can be achieved by analyzing
  the execution information in order to prioritize test cases with novel
  execution traces.


\item \emph{Power schedule:} It is not clear how the power schedule used to
  assign energy to each mutable test case in \fuzzchick works in the context of
  high-level well-typed mutations.
  %
  If it assigns too much energy to certain not-so-interesting seeds, some bugs
  might not be discovered in a timely basis.
  %
  Conversely, assigning too little energy to interesting test cases might cause
  that some bugs cannot be discovered at all unless the right mutation happens
  within the small available energy window --- randomly generating the same test
  case later on does not help, as it becomes uninteresting based on historic
  trace information.

  To keep the comparison fair, the authors replicated the same power schedule
  configuration used in AFL.
  %
  However, AFL uses a different mutation approach that works at the bit level.
  %
  This raises the question about what is the best power schedule configuration
  when using a high-level mutation approach --- something quite challenging to
  characterize in general given the expressivity of the data types used to
  drive the mutators.
\end{itemize}

The next section introduces \mutagen, our CGPT tool written in Haskell that aims
to tackle the main limitations of \fuzzchick using an exhaustive mutation
approach that requires very little randomness and no power schedule.

% ----------------------------------------

\section{\mutagen: Testing Mutants Exhaustively}
\label{sec:mutagen}

In this section we describe the base ideas behind \mutagen, our CGPT tool
written in Haskell.
%
On top of them, Section \ref{sec:heuristics} introduces heuristics that help
finding bugs faster in certain testing scenarios.

In constrast with \fuzzchick, \mutagen does not employ a power schedule to
assign energy to mutable candidates.
%
In turn, it resorts to mutate them in an exhaustive and precise basis, where
%
\begin{inparaenum}
  \item each subexpression of a mutation candidate is associated with a set of
    deterministic mutations, and
  \item for every mutable subexpression, each of these mutations is evaluated
    \emph{exactly once}.
\end{inparaenum}
%
There is a small exception to this rules that we will introduce soon.

This idea is inspired by exhaustive bounded testing tools like SmallCheck (in
Haskell) or Korat (in Java), that produce test cases exhaustively.
%
In simple words, such tools work by enumerating all possible values of the
datatypes used in the testing properties, and then executing them from smaller
to larger until a a bug is found, or a certain size bound is reached.
%
The main problem with this approach is that the space of all possible test cases
often grows exponentially as we increment the size bound, and the user
experiences what it looks like ``hitting a wall'', where no larger test cases
can be evaluated until we exhausted all the immediately smaller ones \cite{feat}.
%
In consequence, such tools can only be applied to relatively simple systems,
where the space of inputs does not grow extremely fast.


Not to be confused by these tools, in \mutagen we do not enumerate all possible
test cases exhaustively.
%
\mutagen uses random generators to find interesting initial seeds, and only then
proceeds to execute all possible mutations.
%
Moreover, these mutants will be mutated further only if they discover new paths
in the target code, so the testing loop automatically prunes the space of test
cases that are worth mutating.


\subsection{Exhaustive Mutations}

To describe \mutagen's testing loop, we first need to introduce the mechanism
used for testing mutations exhaustively.
%
In contrast to \fuzzchick, where mutators are parameterized random generators,
in \mutagen we define mutations as the set of mutants that can be obtained by
altering the input value at the top-level (the root).
%
In Haskell, we define mutations as:

\begin{verbatim}
type Mutation a = a -> [Mutant a]
\end{verbatim}

\noindent Where \texttt{Mutant}s come in two flavours, pure and random:

\begin{verbatim}
data Mutant a = PURE a | RAND (Gen a)
\end{verbatim}

Pure mutants are used most of the time, and encode simple deterministic
transformations over the top-level data constructor of the input --- recursive
mutations will be introduced soon.
%
These tranformation can:
%
\begin{inparaenum}
\item return an immediate subexpression of the same type as the input;
\item swap the top-level data constructor with any other constructor of the same
  type, reusing existing subexpressions; and
\item rearrange and replace fields using existing ones of the same type.
\end{inparaenum}
%
To illustrate this, Fig. \ref{fig:mutagen:mutator} outlines a mutator for the
\texttt{Tree} data type.
%
Notice how this definition simply enumerates mutants that transform the
top-level data constructor, hence no recursion is needed here.
%
Moreover, notice how a default value (\texttt{def}) used to fill the subtrees
when transforming a leaf into a branch.
%
This value corresponds to the smallest value we can construct in order for the
mutant to be type-correct.
%
In practice (\texttt{def = Leaf def}), where the inner \texttt{def} is the
smallest value of the payload --- we use the type class system to abstract this
complexity away in our implementation.
%
Using a default smallest value is again inspired by exhaustive bounded testing
tools, and avoids introducing unnecesary randomness when growing data
constructors.

\begin{figure}
\begin{verbatim}
mutate (Leaf x)     = [ PURE (Node def x def) ]   -- Swap constructor
mutate (Node l x r) = [ PURE l, PURE r            -- Return subexpression
                      , PURE (Leaf x)             -- Swap constructor
                      , PURE (Node l x l)         -- Rearrange subexpressions
                      , PURE (Node r x r)         -- Rearrange subexpressions
                      , PURE (Node r x l) ]       -- Rearrange subexpressions
\end{verbatim}
\caption{\label{fig:mutagen:mutator}\mutagen mutator for the \texttt{Tree} data
  type.}
\end{figure}

At this point, the reader might consider:
%
what about large enumeration types like integers or characters?
%
Does \mutagen transform them exaustively too?
%
\emph{Certainly not.}
%
Random mutants serve as a way to break exhaustiveness when mutating values of
large enumeration types.
%
Instead of trying every possible integer or character, we resolve in using a
random generator and sample a small amount of values from it --- the precise
amount is a tunable parameter of \mutagen.
%
This way, a mutator for integers simply becomes:

\begin{verbatim}
mutate n = [ RAND arbitrary ]
\end{verbatim}


\subsubsection{Mapping top-level mutations everywhere}

So far we defined mutations that transform the root of the input.
%
Now it is time to apply these mutations to every subexpression as well.
%
To do so, we will use two functions that can also be derived from the data type
definition.


In first place, a function \texttt{positions} traverses the mutable candidate
and builds a multi-way tree of mutable positions.
%
These positions are essentially a list of indices encoding the path from the
root to every mutable subexpression.
%
For instance, the positions of a \texttt{Tree} are computed as follows:

\begin{verbatim}
positions (Leaf x)       = node [ (0, positions x) ]
positions (Branch l x r) = node [ (0, positions l), (1, positions x), (2, positions r) ]
\end{verbatim}

\noindent In this light, the mutable positions of the value \texttt{Branch (Leaf 1) 2 (Leaf 3)} are:
%
\begin{equation}
  \nonumber
  {\small \texttt{positions}}\quad
  \left(
  \tikz[
    baseline=-7mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\small \texttt{Branch}}
      child {node {\small \texttt{Leaf}}
        child {node {\small \texttt{1}}}
      }
      child {node {\small \texttt{2}}}
      child {node {\small \texttt{Leaf}}
        child {node {\small \texttt{3}}}
      };
  }
  \right)
  \quad
  =
  \quad
  \tikz[
    baseline=-7mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\texttt{\small []}}
      child {node {\small \texttt{[0]}}
        child {node {\small \texttt{[0,0]}}}
      }
      child {node {\small \texttt{[1]}}}
      child {node {\small \texttt{[2]}}
        child {node {\small \texttt{[2,0]}}}
      };
  }
\end{equation}

\noindent Later, given a desired position to mutate within a candidate, we
define another function \texttt{inside} that precisely finds the subexpression
corresponding to it and applies the mutation.
%
A slightly simplified version of this function for the \texttt{Tree} datatype is
as follows:

\begin{verbatim}
inside []        x              = mutate x
inside (0 : pos) (Leaf x)       = [ Leaf x'       | x' <- inside pos x ]
inside (0 : pos) (Branch l x r) = [ Branch l' x r | l' <- inside pos l ]
inside (1 : pos) (Branch l x r) = [ Branch l x' r | x' <- inside pos x ]
inside (2 : pos) (Branch l x r) = [ Branch l x r' | r' <- inside pos r ]
\end{verbatim}

\noindent This function simply traverses the desired position, calling itself
recursively until it reaches the desired subexpression, where the mutation can
be applied locally at the top-level (case \texttt{inside [] x}).
%
The rest of the function takes care of unwrapping and rewrapping the
intermediate subexpressions and is not partically relevant for the point being
made.


\subsection{Testing loop}

Having the exhaustive mutation mechanism in place, we can finally introduce the
base testing loop used by \mutagen.
%
This is outlined in Algorithm \ref{algo:mutagen:loop}.
%
As it can be observed, we closely follow \fuzzchick's testing loop, using qtwo
queues to keep mutant candidates, and enqueueing and retrieving interesting test
cases from them before falling back to random generation.

\begin{wrapfigure}{r}{0.5\textwidth}
\vspace{-10pt}
\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetKw{KwIn}{in}
  \SetKwFor{KwRepeat}{repeat}{times}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{Muts}{Mutate}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\Muts{x, mut, R}}{
    muts $\gets$ $\varnothing$\;
    \For{pos \KwIn Flatten(Positions(x))}{
      \For{mutant \KwIn Inside(pos, mut, x)}{
        \Switch{mutant}{
          \Case{\texttt{PURE} $\hat{x}$}{
            Enqueue($\hat{x}$, muts)\;
          }
          \Case{\texttt{RAND} gen}{
            \KwRepeat{R}{
              $\hat{x}$ $\gets$ Sample(gen)\;
              Enqueue($\hat{x}$, muts)\;
            }
          }
        }
      }
    }
    \KwRet muts\;
  }
\caption{\label{algo:mutagen:init}Mutants Initialization}
\end{algorithm}
\vspace{-10pt}
\end{wrapfigure}


The main difference lies in that we precompute all the mutations of a given
mutation candidate before enqueueing them.
%
These mutations are put together into lists that we call \emph{mutation batches}
--- one for each mutation candidate.
%
To initialize a mutation batch (outlined in Algorithm \ref{algo:mutagen:init}),
we first flatten all the mutable positions of the input value in level order
(recall that positions are stored as a multi-way tree).
%
Then, we iterate over all of them and retrieve all the mutants defined for each
subexpression.
%
For each one of these, there are two posible cases:
%
\begin{inparaenum}
\item if it is a pure mutant carrying a concrete mutated value, we enqueue it
  into the mutation batch directly; otherwise
\item it is a random mutant that carries a random generator with it (e.g., a
  numeric subexpression), in which case we sample and enqueue \textit{R} random
  values using this generator, where \textit{R} is a parameter set by the user.
\end{inparaenum}
%
At the end, we simply return the accummulated batch.


Finally, the seed selection algorithm (Algorithm \ref{algo:mutagen:pick}) simply
selects the next test case using the same criteria as \fuzzchick, prioritizing
valid candidates over discarded ones, falling back to random generation when
both queues are empty.
%
Since mutations are precomputed, this function only needs to pick the next test
case from the current batch, until it becomes empty and can switch to the next
precomputed one in line.


\begin{figure}[b]
\begin{multicols}{2}

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{MG}{Loop}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\MG{P, N, R, gen, mut}}{
    i $\gets$ 0\;
    TLog, QSucc, QDisc $\gets$ $\varnothing$;\;
    \While{i $<$ N}{
      x $\gets$ Pick(QSucc, QDisc, gen, mut)\;
      (result, trace) $\gets$ WithTrace(P(x))\;
      \lIf{\KwNot result}{\KwRet Bug(x)}
      \If{Interesting(TLog, trace)}{
        \If{\KwNot Discarded(result)}{
          muts $\gets$ Mutants(x, mut, R)\;
          Enqueue(QSucc, muts)\;
        }
        \uElseIf{Passed(Parent(x))}{
          muts $\gets$ Mutate(x, mut, R)\;
          Enqueue(QDisc, muts)\;
        }
      }
      i $\gets$ i+1\;
    }
    \KwRet Ok\;
  }
\caption{\label{algo:mutagen:loop}\mutagen Testing Loop}
\end{algorithm}

\columnbreak

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{Pick}{Pick}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\Pick{QSucc, QDisc, gen}}{
    \If{\KwNot Empty(QSucc)}{
      muts $\gets$ Deque(QSucc)\;
      \If{Empty(muts)}{
        Pick(QSucc, QDisc, gen)\;
      } \uElse{
        PushFront(QSucc, Rest(muts))\;
        \KwRet First(muts)\;
      }
    }
    \If{\KwNot Empty(QSucc)}{
      muts $\gets$ Deque(QSucc)\;
      \If{Empty(muts)}{
        Pick(QSucc, QDisc, gen)\;
      } \uElse{
        PushFront(QSucc, Rest(muts))\;
        \KwRet First(muts)\;
      }
    }
    \lElse{\KwRet Sample(gen)}
  }
\caption{\label{algo:mutagen:pick}\mutagen Seed Selection}
\vspace{1pt}
\end{algorithm}
\end{multicols}
\end{figure}

Another small difference between \mutagen and \fuzzchick is the criteria for
enqueuing discarded tests.
%
We found that, especially for large data types, the queue of discarded
candidates tends to grow disproportionately during testing, making them hardly
usable and consuming large amounts of memory.
%
To improve this, we resort to mutate discarded tests cases only when we have
some evidence that they are ``almost valid.''
%
For this, each mutated test case remembers whether its parent (the original test
case they derive from after being mutated) was valid.
%
Then, we enqueue discarded test cases only if they meet this condition.
%
As a result, we fill the discarded queue with lesser but much more interesting
mutation candidates.
%
Moreover, this can potentially help introducing \emph{2-step mutations}, where
an initial mutation breaks a valid test case in a small way, it gets enqueued as
discarded, and later a subsequent mutation fixes it by changing a different
subexpression.


The next section introduces two heurisitics we added to the base testing loop of
\mutagen based on the limitations we found in \fuzzchick.
%
%% These heuristics can that offer a substantial improvement in practice.

% ----------------------------------------

\section{\mutagen Heuristics}
\label{sec:heuristics}

In this section we introduce two heuristics implemented on top of the base
testing loop of our tool.
%
\mutagen enables them all by default, although they can be individually disabled
by the user if deemed appropriate.

\subsection{Priority FIFO Scheduling}

This heuristic tackles the issue of enqueuing novel mutation candidates at the
end of (possibly) long queues of not-so-interesting previously executed ones.

\fuzzchick uses AFL instrumentation under the hood, which in turn uses an
\emph{edge coverage} criteria to distinguish novel executions and to assign each
mutation candidate a given energy.
%
In contrast, execution traces \mutagen represent the \emph{path} in the code
taken by the program, as opposed to just the set of edges traversed in the
control-flow graph (CFG).
%
Using this criteria lets us gather precise information from the each new
execution.
%
%% To keep track of the execution path of each test, our tool keeps an internal
%% prefix tree that records every new entry by traversing this data structure and
%% inserting new nodes after a new path prefix gets discovered.
%% %
In particular, we are interested in the \emph{depth} where each new execution
branches from already seen ones.
%
Our assumption here is that test cases that differ (branch) at shallower depths
from the ones already executed are more likely to discover completely new
portions of the code under test, and hence we want to assign them a higher
priority.


In this light, every time we insert a new execution path into the internal trace
log, we calculate the number of new nodes that were executed, as well as the
\emph{branching depth} where they got inserted.
%
The former is used to distinguish interesting test cases (whether or not new
nodes were inserted), whereas the latter is used by this heuristic to schedule
mutation candidates.
%
Fig. \ref{fig:mutagen:tracelog} illustrates this idea, inserting two execution
traces (one after another) into a trace log that initially contains a single
execution path.
%
The second insertion (with trace $1 \rightarrow 2 \rightarrow 6 \rightarrow 7$)
branches at a shallower depth than the first one (2 vs. 3), hence its
corresponding test case should be given a higher priority.

\begin{figure}[b]
\newcommand\stacked[2]{\underset{\textstyle #2\mathstrut}{#1}}
\begin{equation}
  \nonumber
  \left[
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\small \texttt{1}}
      child {node {\small \texttt{2}}
        child {node {\small \texttt{3}}
          child {node {\small \texttt{4}}}
        }
      }
  }
  \right]
  \;
  +
  \;
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\small \texttt{1}}
      child {node {\small \texttt{2}}
        child {node {\small \texttt{3}}
          child {node {\small \texttt{5}}}
        }
      }
  }
  \;
  =
  \;
  \left[
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\color{red} \small \texttt{1}}
      child {node {\color{red} \small \texttt{2}}
        child {node {\color{red} \small \texttt{3}}
          child {node {\small \texttt{4}}}
          child {node {\color{blue} \small \texttt{5}}}
        }
      }
  }
  \right]
  ,
  \stacked{{\color{blue} new=1\phantom{x}}}{{\color{red} depth=3}}
  \qquad
  \qquad
  \left[
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\small \texttt{1}}
      child {node {\small \texttt{2}}
        child {node {\small \texttt{3}}
          child {node {\small \texttt{4}}}
          child {node {\small \texttt{5}}}
        }
      }
  }
  \right]
  \;
  +
  \;
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=0.75cm}
  ]{
    \node {\small \texttt{1}}
      child {node {\small \texttt{2}}
        child {node {\small \texttt{6}}
          child {node {\small \texttt{7}}
          }
        }
      }
  }
  \;
  =
  \;
  \left[
  \tikz[
    baseline=-10mm,
    level distance=0.6cm,
    level 1/.style={sibling distance=0.75cm},
    level 2/.style={sibling distance=1cm}
  ]{
    \node {\color{red} \small \texttt{1}}
      child {node {\color{red} \small \texttt{2}}
        child {node {\small \texttt{3}}
          child {node {\small \texttt{4}}}
          child {node {\small \texttt{5}}}
        }
        child {node {\color{blue}\small \texttt{6}}
          child {node {\color{blue}\small \texttt{7}}}
        }
      }
  }
  \right]
  ,
  \stacked{{\color{blue} new=2\phantom{x}}}{{\color{red} depth=2}}
\end{equation}
\caption{\label{fig:mutagen:tracelog}Inserting two new execution traces into the
  internal trace log (represented using brackets).}
\end{figure}

With this mechanism in place, we can modify \mutagen's base testing loop by
replacing each mutation queue with a priority queue indexed by the branching
depth of each new execution.
%
These changes are illustrated in Algorithm \ref{algo:mutagen:fifo}.
%
Statements in {\color{red} red} indicate important changes to the base
algorithm, whereas ellipses denote parts of the code that are not relevant for
the point being made.


To pick the next test case, we simply retrieve the one with highest priority
(the smallest branching depth).
%
Then, whenever we find a new interesting test case, we enqueue it at the
beginning of the queue of its corresponding priority.
%
This allows the testing loop to jump immediately onto processing new interesting
candidates as soon as they are found (even at the same priority), and to jump
back to previous candidates as soon as their mutants become progressively less
novel.

\begin{figure}
\begin{multicols}{2}

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{MG}{Loop}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\MG{P, N, R, gen, mut}}{
    $\cdots$\;
    x $\gets$ Pick(QSucc, QDisc, gen, mut)\;
    (result, trace) $\gets$ WithTrace(P(x))\;
    $\cdots$\;
    \If{Interesting(TLog, trace)}{
      \If{\KwNot Discarded(result)}{
        muts $\gets$ Mutants(x, mut, R)\;
        {\color{red} prio $\gets$ BranchDepth(TLog, trace)}\; %% NEW
        {\color{red} PushFront(QSucc, prio, muts)}\;          %% NEW
      }
      $\cdots$\;
    }
  }
  \vspace{5pt}
  \SetKwFunction{Pick}{Pick}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\Pick{QSucc, QDisc, gen}}{
    \If{\KwNot Empty(QSucc)}{
      {\color{red} (muts, prio) $\gets$ DequeMin(QSucc)}\; %%NEW
      \If{Empty(muts)}{
        Pick(QSucc, QDisc, gen)\;
      } \uElse{
        {\color{red} PushFront(QSucc, prio, Rest(muts))}\; %% NEW
        \KwRet First(muts)\;
      }
    }
    $\cdots$\;
  }

\caption{\label{algo:mutagen:fifo}Priority FIFO Heuristic}
\end{algorithm}

\columnbreak

\begin{algorithm}[H]
  \SetArgSty{textnormal}
  \SetInd{0em}{0.75em}
  \SetKw{KwNot}{not}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{MG}{Loop}
  \SetKwProg{Fn}{Function}{:}{}
  \Fn{\MG{P, N, gen, mut}}{
    {\color{red}
    boring  $\gets$ 0\;
    reset   $\gets$ 1000\;
    R       $\gets$ 1\;
    }
    $\cdots$\;
    \While{i $<$ N}{
      {\color{red}
      \If{boring $>$ reset}{
        TLog   $\gets$ $\varnothing$\;
        reset $\gets$ reset * 2\;
        R     $\gets$ R * 2\;
      }
      }
      $\cdots$\;
      \lIf{\KwNot result}{\KwRet Bug(x)}
      \If{Interesting(TLog, trace)}{
        {\color{red} boring  $\gets$ 0}\;
        $\cdots$\;
      }
      \lElse {
        {\color{red} boring $\gets$ boring + 1}
      }
      $\cdots$\;
    }
  }

\caption{\label{algo:mutagen:reset}Trace Saturation Heuristic}
\end{algorithm}

\end{multicols}
%% \caption{\label{fig:heuristics} The two main heuristics implemented in \mutagen.
%%   Statements in {\color{red} red} indicate important changes to the base
%%   algorithm. Ellipses denote parts of the code that are not relevant for the
%%   point being made. }
\end{figure}


\subsection{Detecting Trace Space Saturation And Tuning Random Mutations}

As introduced in Section \ref{sec:mutagen}, our tool is parameterized by the
amount of random mutations to be generated over each mutable subexpression
defined using a random mutant, e.g., numeric values, characters, etc.
%
But, how many random mutations should we use? A single one? A few tenths? A few
hundreds?
%
Clearly, using too little, can put finding bugs at risk.
%
For instance, when the system under test branches on numeric values, we should
make sure that we set enough random mutations to test each case in a reasonable
basis.
%
Using too many, the other hand, can degrade the performance of the testing
loop, as it will spend too much time producing uninteresting mutations.
%
This can happen for instance if the subexpressions defined using random mutants
are only used as payloads, and their value does not affect the execution in any
way.


Answering this question precisely is not an easy task, and the second heuristic
we introduce in this work aims to tackle this issue.
%
We found that, the smaller the number of random mutations we set, the easier it
is for the trace log that records executions to start getting saturated, i.e.,
when interesting test cases stop getting discovered or are discovered very
sporadically.
%
Our realization is that we can use this information to automatically optimize
the number of random mutations used by our tool.
%
This idea is described in Algorithm \ref{algo:mutagen:reset}.
%
The process is simple:
%
\begin{inparaenum}
  \item we start the testing loop with the amount of random mutations set to one,
  %
  \item each time we find that a test is not interesting (i.e. boring), we
    increment a counter,
  \item if we have not produced any interesting test case after a certain
    threshold (1000 tests seems to be a reasonable value in practice), we
    increment the amount of random mutations and the threshold by twice the
    current amount.
    %
    Additionally, each time this happens we also reset the trace log, so
    interesting test cases found on a previous iteration can be found and
    enqueued for mutation again --- this time with a higher effort dedicated to
    producing random mutations.
\end{inparaenum}

Then, if the execution of the system under test depends heavily on the values
stored at randomly mutable subexpressions, starting with a single random mutation
will quickly saturate the trace space, and this heuristic will continuosly
increase the random mutations parameter until that stops happening.

%% \subsection{Mutation Inheritance}

%% The last heuristic we discuss in this work attempts to reduce the amount of
%% mutations required when testing properties that lazily consume foldable inputs
%% like lists or trees.
%% %
%% To illustrate this, suppose we define a property that aims to test a list
%% sorting algorithm:


% ----------------------------------------

\section{Case studies}
\label{sec:casestudies}

Aliquam erat volutpat \citep{devai2013edsl}. Nunc eleifend leo vitae magna. In id
erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut,
lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus.
Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque
nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a,
aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet
tortor. Nam euismod tellus id erat.

\subsection{IFC Stack Machine}

Pellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel
tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac
leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu,
wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula
mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce
commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit,
vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis,
varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat
tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus
lacinia purus, et dictum nunc justo sit amet elit.

\subsection{WebAssembly Engine}

Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec facilisis
facilisis, est dui fermentum leo, quis tempor ligula erat quis odio. Nunc porta
vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum. Aliquam posuere.
Nunc aliquet, augue nec adipiscing interdum, lacus tellus malesuada massa, quis
varius mi purus non odio. Pellentesque condimentum, magna ut suscipit hendrerit,
ipsum augue ornare nulla, non luctus diam neque sit amet urna. Curabitur
vulputate vestibulum lorem. Fusce sagittis, libero non molestie mollis, magna
orci ultrices dolor, at vulputate neque nulla lacinia eros. Sed id ligula quis
est convallis tempor. Curabitur lacinia pulvinar nibh. Nam a sapien.

\subsubsection{Testing the WebAssembly Validator}

Nullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec facilisis
facilisis, est dui fermentum leo, quis tempor ligula erat quis odio. Nunc porta
vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum. Aliquam posuere.
Nunc aliquet, augue nec adipiscing interdum, lacus tellus malesuada massa, quis
varius mi purus non odio. Pellentesque condimentum, magna ut suscipit hendrerit,
ipsum augue ornare nulla, non luctus diam neque sit amet urna. Curabitur
vulputate vestibulum lorem. Fusce sagittis, libero non molestie mollis, magna
orci ultrices dolor, at vulputate neque nulla lacinia eros. Sed id ligula quis
est convallis tempor. Curabitur lacinia pulvinar nibh. Nam a sapien.


\begin{verbatim}
prop_validator m =
  isValidHaskell m ==> isValidSpec m
\end{verbatim}

Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.

\begin{verbatim}
isValidHaskell m =
  case validate m of
    Left  validationError -> return False
    Right validModule     -> return True
\end{verbatim}

Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.

\begin{verbatim}
isValidSpec m = do
  writeFile "testcase.wasm" (dumpModule m)
  res <- shell "./wasm" ["-d", "-i", "testcase.wasm"]
  return (res == "")
\end{verbatim}

Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.


\subsubsection{Testing the WebAssembly Interpreter}

Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.


\begin{verbatim}
mk_module ty name fun =
  emptyModule { types     = [ ty ]
              , functions = [ fun ]
              , exports   = [ Export name (ExportFunc 0) ]
              , mems      = [ Memory (Limit 1 Nothing) ]
              }
\end{verbatim}

\begin{verbatim}
prop_interpreter ty (args, fun) =
  discardAfter 20
  (do let m = mk_module ty "f" fun;
      resHs   <- invokeHaskell m "f" args;
      resSpec <- invokeSpec    m "f" args;
      return (equiv resHs resSpec))
\end{verbatim}

\begin{verbatim}
prop_interpreter_i32 (i, f, fun) =
  prop_interpreter
    (FuncType { params = [I32, F32], result = [I32]})
    ([VI32 i, VF32 f], fun)
\end{verbatim}


\subsubsection{Real Bugs and Discrepancies found by \mutagen in \textit{haskell-wasm}}

\paragraph{Bug \#1: Invalid Memory Alignment Validation}
Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Donec hendrerit tempor
tellus. Donec pretium posuere tellus. Proin quam nisl, tincidunt et, mattis
eget, convallis nec, purus. Cum sociis natoque penatibus et magnis dis
parturient montes, nascetur ridiculus mus. Nulla posuere. Donec vitae dolor.
Nullam tristique diam non turpis. Cras placerat accumsan nulla. Nullam rutrum.
Nam vestibulum accumsan nisl.

\paragraph{Bug \#2: Lax invocation checks}
Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.


\paragraph{Bug \#3: Allowed Out-of-bounds Memory Access}
Pellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel
tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac
leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu,
wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula
mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce
commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit,
vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis,
varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat
tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus
lacinia purus, et dictum nunc justo sit amet elit.

\paragraph{Discrepancy \#1: Different Reinterpretation Semantics of NaN Values}
Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Donec hendrerit tempor
tellus. Donec pretium posuere tellus. Proin quam nisl, tincidunt et, mattis
eget, convallis nec, purus. Cum sociis natoque penatibus et magnis dis
parturient montes, nascetur ridiculus mus. Nulla posuere. Donec vitae dolor.
Nullam tristique diam non turpis. Cras placerat accumsan nulla. Nullam rutrum.
Nam vestibulum accumsan nisl.

\paragraph{Discrepancy \#2: Allowed Blocks with Multiple Return Types}
Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Donec hendrerit tempor
tellus. Donec pretium posuere tellus. Proin quam nisl, tincidunt et, mattis
eget, convallis nec, purus. Cum sociis natoque penatibus et magnis dis
parturient montes, nascetur ridiculus mus. Nulla posuere. Donec vitae dolor.
Nullam tristique diam non turpis. Cras placerat accumsan nulla. Nullam rutrum.
Nam vestibulum accumsan nisl.

\section{Evaluation}
\label{sec:evaluation}

\subsection{IFC Stack Machine}

Aliquam erat volutpat \citep{devai2013edsl}. Nunc eleifend leo vitae magna. In
id erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut,
lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus.
Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque
nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a,
aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet
tortor. Nam euismod tellus id erat.

\begin{center}
  \includegraphics[width=\linewidth]{tikz/ifc-mttf.tikz}
  \includegraphics[width=\linewidth]{tikz/ifc-fr.tikz}
\end{center}

\subsection{Webassembly Engine}

Aliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci
commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget,
lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac
felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui
dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet
quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor.
Nam euismod tellus id erat.

\begin{center}
  \includegraphics[width=\linewidth]{tikz/wasm-mttf.tikz}
  \includegraphics[width=\linewidth]{tikz/wasm-fr.tikz}\vspace{-5pt}
  \includegraphics[width=\linewidth]{tikz/wasm-legend.tikz}
\end{center}

% ----------------------------------------

%% \section{Implementation}
%% \label{sec:implementation}

%% \subsection{Deriving Mutation Machinery}

%% Integer placerat tristique nisl. Praesent augue. Fusce commodo. Vestibulum
%% convallis, lorem a tempus semper, dui dui euismod elit, vitae placerat urna
%% tortor vitae lacus. Nullam libero mauris, consequat quis, varius et, dictum id,
%% arcu. Mauris mollis tincidunt felis. Aliquam feugiat tellus ut neque. Nulla
%% facilisis, risus a rhoncus fermentum, tellus tellus lacinia purus, et dictum
%% nunc justo sit amet elit.

%% \subsection{Tracing Haskell Programs}

%% \begin{verbatim}
%%   sorted []       = True
%%   sorted [x]      = True
%%   sorted (x:y:xs) = if x <= y then sorted (y:xs) else False
%% \end{verbatim}

%% \begin{verbatim}
%%   sorted []       = _trace_ 1 (True)
%%   sorted [x]      = _trace_ 2 (True)
%%   sorted (x:y:xs) = _trace_ 3 (if x <= y then _trace_ 4 (sorted (y:xs)) else _trace_ 5 (False))
%% \end{verbatim}

%% Pellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel
%% tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac
%% leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu,
%% wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula
%% mollis ultricies.

% ----------------------------------------

\section{Related work}
\label{sec:related}


\subsection{Grammar-based Fuzzing}

Pellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel
tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac
leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu,
wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula
mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce
commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit,
vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis,
varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat
tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus
lacinia purus, et dictum nunc justo sit amet elit.

\subsection{Random Data Generation}

%% Don't forget to cite "Deriving good generators ..."

Pellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel
tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac
leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu,
wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula
mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce
commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit,
vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis,
varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat
tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus
lacinia purus, et dictum nunc justo sit amet elit.

\subsection{Exhaustive Bounded Testing}

Aliquam erat volutpat \citep{devai2013edsl}. Nunc eleifend leo vitae magna. In id
erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut,
lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus.
Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque
nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a,
aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet
tortor. Nam euismod tellus id erat.

% ----------------------------------------

\section{Conclusions}
\label{sec:conclusions}

Aliquam erat volutpat \citep{devai2013edsl}. Nunc eleifend leo vitae magna. In id
erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut,
lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus.
Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque
nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a,
aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet
tortor. Nam euismod tellus id erat.

% ----------------------------------------

%% The acknowledgments section is defined using the "acks" environment (and NOT
%% an unnumbered section). This ensures the proper identification of the section
%% in the article metadata, and the consistent spelling of the heading.

%% \begin{acks}
%% To Robert, for the bagels and explaining CMYK and color spaces.
%% \end{acks}

% ----------------------------------------

%% The next two lines define the bibliography style to be used, and the
%% bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

% ----------------------------------------

%% If your work has an appendix, this is the place to put it.
\appendix

\section{Detailed Empirical Results}

Fusce suscipit, wisi nec facilisis facilisis, est dui fermentum leo, quis tempor
ligula erat quis odio. Nunc porta vulputate tellus. Nunc rutrum turpis sed pede.
Sed bibendum. Aliquam posuere. Nunc aliquet, augue nec adipiscing interdum,
lacus tellus malesuada massa, quis varius mi purus non odio. Pellentesque
condimentum, magna ut suscipit hendrerit, ipsum augue ornare nulla, non luctus
diam neque sit amet urna. Curabitur vulputate vestibulum lorem. Fusce sagittis,
libero non molestie mollis, magna orci ultrices dolor, at vulputate neque nulla
lacinia eros. Sed id ligula quis est convallis tempor. Curabitur lacinia
pulvinar nibh. Nam a sapien.

\end{document}
\endinput
%%
%% End of `main.tex'.
